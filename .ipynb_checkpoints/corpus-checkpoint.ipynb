{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes\n",
    "\n",
    "When working with a corpus of texts it can quickly become confusing to keep track of which step in an NLP pipeline you are on. Say you want to run a Frequency Distribution, did you remeber to tokenize the text? To pull out the stopwords? While this is simple enough if you are working with a small group of texts in a discrete timeperiod, this becomes exponentially more challenging when working with a large body of texts or when working over a longer period of time. Matters become even more complicated if you want to switch between corpus-level analysis and text-level analysis. The realities of your project may quickly mean that manually performing each step in your pipeline becomes redundant, hard to keep track of, or a waste of time. This is where classes come in. \n",
    "\n",
    "Utilizing classes allows you to store the qualities of your corpus (it's \"attributes\") and instructions for things you want to execute on those attributes (called \"methods\") in a file that can be run as a module in the interpreter. Ultimately, using classes allows you to more easily organize text level and corpus level functions, is easier to grasp when working at scale, and allows you to store your parameters so you can effectently scale up your NLP abilites. \n",
    "\n",
    "Classes can be as simple or as complex as you want them to be. In the following template, we will define a \"Corpus\" and a \"Text\" class and assign to each class the different attributes we want it to contain and sample methods that might commonly be executed within an NLP project on those attributes. \n",
    "\n",
    "The first code block is a class code template. This script could be saved as a file in your working directory and updated as neccessary. The subsequent blocks of code can be used in the interpreter to import the class as a module or to reload the class after any changes are made to yhe file. The module and the file (with extension .py behind it) will have the same name. We have named this file class_practice.py\n",
    "\n",
    "Please note that this code will not run in the notebook. Feel free to save it into your own file or to copy and paste as is useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "\n",
    "class Corpus(object):\n",
    "    # rather than enter the data bit by bit, we create a constructor that takes in the data at one time\n",
    "    # all the attributes we want the class to have follow the __init__ syntax\n",
    "    def __init__(self, corpus_dir):\n",
    "        self.dir = corpus_dir # where corpus_dir is your corpus' filepath\n",
    "        # classes may contain functions we define ourselves, the all_files function is defined below\n",
    "        self.filenames = self.all_files()\n",
    "        # this attribute combines multiple parameters (is this the right word?) it calls nltk's built-in list of English stopwords, something built in from string?, and quotation marks\n",
    "        self.stopwords = nltk.corpus.stopwords.words('english') + [char for char in string.punctuation] + ['``', \"''\"]\n",
    "        # limits to the first four texts, helpful to quickly check things in large corpuses\n",
    "        self.texts = [Text(fn, self.stopwords) for fn in self.filenames[0:3]]\n",
    "\n",
    "    def all_files(self):\n",
    "        \"\"\"given the corpus_dir, return the filenames in it\"\"\"\n",
    "        texts = []\n",
    "        for (root, _, files) in os.walk(self.dir):\n",
    "            for fn in files:\n",
    "                path = os.path.join(root, fn)\n",
    "                texts.append(path)\n",
    "        return texts\n",
    "\n",
    "# the Text class works the same as the Corpus, but will contain text-level only attributes\n",
    "class Text(object):\n",
    "    def __init__(self, fn, stopwords):\n",
    "        self.filename = fn\n",
    "        self.raw_text = self.get_text() \n",
    "        self.raw_tokens = nltk.word_tokenize(self.raw_text)\n",
    "        self.cleaned_tokens = self.clean_tokens(stopwords)\n",
    "        self.nltk_text = nltk.Text(self.cleaned_tokens)\n",
    "        \n",
    "    def get_text(self):\n",
    "        with open(self.filename) as fin:\n",
    "            return fin.read()\n",
    "    \n",
    "    def clean_tokens(self, stopwords):\n",
    "        return [token.lower() for token in self.raw_tokens if token not in stopwords]\n",
    "        \n",
    "# this is what is ran if you run the file as a one-off event from the terminal, $ python3 class_practice.py\n",
    "def main():\n",
    "    corpus_dir = 'corpus/'\n",
    "    print('This is being run from the command line.') # anything that you might want to jump to, such as a graph, FreqDist, etc. would go here\n",
    "\n",
    "# this allows you to import the classes as a module. it uses the special built-in variable __name__ set to the value \"__main__\" if the module is being run as the main program\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The payoff of organzing your project within classes is that you can run them as a module from the interpreter. To do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the script as a module in the interpreter\n",
    "import class_practice # file name without the extension\n",
    "# instantiate the Corpus template as class_practice, store as a varaible named this_corpus\n",
    "this_corpus = class_practice.Corpus()\n",
    "\n",
    "# replace \"self\" with \"this_corpus\" to call the methods\n",
    "this_corpus.dir # will show the directory of the corpus\n",
    "this_corpus.filenames # returns all the filenames in the corpus\n",
    "\n",
    "# to work with the text class, instantiate the particular text you want to use\n",
    "illiad = class_practice.Text('corpus/illiad.xml')\n",
    "\n",
    "# or you can instantiate a text by call its index in the corpus\n",
    "class_practice.Text(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you make changes to your class_practice file, you have to re-import it into python and re-instantiate your classes. This makes sure you are running the most up-to-date version of your file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(class_practice)\n",
    "\n",
    "#re-instantiate the corpus or text\n",
    "this_corpus = class_practice.Corpus()\n",
    "illiad = class_practice.Text('corpus/illiad.xml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
