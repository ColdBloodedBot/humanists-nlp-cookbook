{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code finds a specific word in a TEI document and returns the word in its context within the work. The size of the contextualized result is ultimately up to you, and will change depending on the type of work you are consulting and the TEI schema used. The example text, Homer's Iliad as translated by Alexander Pope uses paragraph divisions for the introduction and line divisions for the main text. Our inquiry will be within the main text so the code is written assuming line divisions. \n",
    "\n",
    "For more information on handling XML files in Python, consult the XML page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Natural Language Toolkit and the Beautiful Soup library\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# store the text's filepath\n",
    "filename = 'corpus/iliad.tei' \n",
    "\n",
    "# read in the filename, store it temporarily as a variable called text.\n",
    "with open(filename, 'r') as fin:\n",
    "    text = fin.read()\n",
    "\n",
    "# take the text, turn it into a BeautifulSoup object, and store in a variable called tei.\n",
    "tei = BeautifulSoup(text, 'xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will store the text divisions we are interested in according to the tags used by our TEI schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = tei.find_all('l')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to call NLTK to tokenize the content of the tags: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a blank list for lines\n",
    "line_tokens = []\n",
    "\n",
    "# loop over the lines, tokenize their content, append the tokens to the blank list\n",
    "for line in lines:\n",
    "    sentences = nltk.sent_tokenize(lines.text)\n",
    "    line_tokens.append(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the word of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_of_interest = 'Apollo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store our contextual parameters and loop over token list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a blank list to store results\n",
    "contexts_of_word_of_interest = []\n",
    "\n",
    "# store context paramater\n",
    "context = 10\n",
    "\n",
    "# loop over line_tokens list, retrieve the index and the vaule of each iteration of word_of_choice\n",
    "for num, line in enumerate(line_tokens, start=1):\n",
    "    for sentence in line:\n",
    "        if sentence.count(word_of_interest)>0:\n",
    "            # append the contextualized index according to the context parameters\n",
    "            start = num - context\n",
    "            end = num + context\n",
    "            contexts_of_word_of_interest(line_tokens[start:end])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of reading, the following print statement is helpful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in contexts_of_word_of_interest:\n",
    "    print('======')\n",
    "    print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
