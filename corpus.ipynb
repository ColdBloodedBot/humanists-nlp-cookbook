{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with a corpus. This corpus template was taekn from the animorphs corpus work. You could get way more involved with it. Might be good to thinkk about what of this is the bare minimum and what could go further. Also note that this won't run in cell with the main piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "\n",
    "class Corpus(object):\n",
    "    def __init__(self, corpus_dir):\n",
    "        self.dir = corpus_dir\n",
    "        self.filenames = self.all_files()\n",
    "        self.stopwords = nltk.corpus.stopwords.words('english') + [char for char in string.punctuation] + ['``', \"''\"]\n",
    "        # for testing limiting to the first few texts\n",
    "        self.texts = [Text(fn, self.stopwords) for fn in self.filenames[0:3]]\n",
    "\n",
    "    def all_files(self):\n",
    "        \"\"\"given the corpus_dir, return the filenames in it\"\"\"\n",
    "        texts = []\n",
    "        for (root, _, files) in os.walk(self.dir):\n",
    "            for fn in files:\n",
    "                path = os.path.join(root, fn)\n",
    "                texts.append(path)\n",
    "        return texts\n",
    "    \n",
    "class Text(object):\n",
    "    def __init__(self, fn, stopwords):\n",
    "        self.filename = fn\n",
    "        self.raw_text = self.get_text()\n",
    "        self.raw_tokens = nltk.word_tokenize(self.raw_text)\n",
    "        self.cleaned_tokens = self.clean_tokens(stopwords)\n",
    "        self.nltk_text = nltk.Text(self.cleaned_tokens)\n",
    "\n",
    "        \n",
    "    def get_text(self):\n",
    "        with open(self.filename) as fin:\n",
    "            return fin.read()\n",
    "    \n",
    "    def clean_tokens(self, stopwords):\n",
    "        return [token.lower() for token in self.raw_tokens if token not in stopwords]\n",
    "        \n",
    "    \n",
    "def main():\n",
    "    corpus_dir = 'corpus/'\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
