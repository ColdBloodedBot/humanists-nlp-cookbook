{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with a folder of files\n",
    "\n",
    "Many common tutorials tell you how to work with a single file, but a new student might quickly want to scale up beyond a single text. In this folder we have a folder 'corpus' with three texts by Virginia Woolf in it. If you're comfortable with regular expressions you could use the glob library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus/\n",
      "['corpus/1922_jacobs_room.txt', 'corpus/sonnet_one.txt', 'corpus/1915_the_voyage_out.txt', 'corpus/1919_night_and_day.txt']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "folder_path = 'corpus/'\n",
    "extension = '*.txt'\n",
    "print(folder_path)\n",
    "print(glob.glob(folder_path + extension))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to work with a larger array of files (or you don't want to deal with regular expressions) you can define your own function to return all the files in a particular folder and nuance it as you would like. The os library allows you to do such things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['corpus/1922_jacobs_room.txt', 'corpus/.muck', 'corpus/sonnet_one.txt', 'corpus/1915_the_voyage_out.txt', 'corpus/1919_night_and_day.txt', 'corpus/sonnets/sonnet_two.txt', 'corpus/sonnets/sonnet_five.txt', 'corpus/sonnets/sonnet_four.txt', 'corpus/sonnets/sonnets_three.txt', 'corpus/sonnets/sonnet_one.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def all_files(folder_name):\n",
    "    \"\"\"given a directory, return the filenames in it\"\"\"\n",
    "    texts = []\n",
    "    for (root, _, files) in os.walk(folder_name):\n",
    "        for fn in files:\n",
    "            path = os.path.join(root, fn)\n",
    "            texts.append(path)\n",
    "    return texts\n",
    "\n",
    "# now we try it\n",
    "print(all_files('corpus'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While glob.glob() and os.walk might appear to do similar things, there is an important distinction to be made between them. os.walk will walk a director recursively, meaning that, if the given folder contains other folders, your script will crawl through every subfolder to pull out every contained file. glob.glob() will only give you the files that match the gvien regular expression, so it will _not_ navigate the directory structure to find the contents of subfolders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot files\n",
    "\n",
    "But wait? What is that .muck file doing there? A file whose name is prefixed with a dot will be hidden from the graphical user interface (GUI). ie. you won't see that file in the desktop. Normally this is fine, but sometimes they can unexpectedly cause issues when working with the file structure from within Python. In particular, .DS_Store is a hidden file produced by Macs and that stores information about the current view (the computer has to store the fact that you want to view a window as icons somewhere!). You'll want to ignore those files that start with hidden characters so that you only work with the ones you care about. In this case, we can add an if statement to the function we defined to take care of this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['corpus/iliad.tei', 'corpus/brothers_karamazov.tei', 'corpus/1922_jacobs_room.txt', 'corpus/sonnet_one.txt', 'corpus/1915_the_voyage_out.txt', 'corpus/16663-tei.tei.xml', 'corpus/1919_night_and_day.txt', 'corpus/sonnets/sonnet_two.txt', 'corpus/sonnets/sonnet_five.txt', 'corpus/sonnets/sonnet_four.txt', 'corpus/sonnets/sonnets_three.txt', 'corpus/sonnets/sonnet_one.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def all_files(folder_name):\n",
    "    \"\"\"given a directory, return the filenames in it\"\"\"\n",
    "    texts = []\n",
    "    for (root, _, files) in os.walk(folder_name):\n",
    "        for fn in files:\n",
    "            if fn[0] == '.': # a new addition!\n",
    "                pass\n",
    "            else:\n",
    "                path = os.path.join(root, fn)\n",
    "                texts.append(path)\n",
    "    return texts\n",
    "\n",
    "# now we try it\n",
    "print(all_files('corpus'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, a filename is just a string in this case. And strings are iterable in Python, meaning we can treat a filename like a sequence (a list) of characters. So take the lines that I've marked 'a new addition.' This section checks the first character of each filename. If we've got a period in that slot, we're looking at a hidden dot file that we don't care about. So we move along to the next item in the collection. If there is no period in that first slot we append it to the list of files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Deleting Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides reading in files, you often have to create new files for your results, analysis, or processed data. While you can, of course, make new files using the terminal or finder, it is often preferable to make files from inside your Python script. After all, you might want, say, to name your new files dynamically based on the results of your analysis. We can do this, again, by using the `os` library in conjunction with some basic Python functionality. \n",
    "\n",
    "Making files is something you can already do with the basic Python library. As long as we have our data in a string we can write it into the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can write this data to a new file by storing it as a string.\n"
     ]
    }
   ],
   "source": [
    "data_to_write = \"We can write this data to a new file by storing it as a string.\"\n",
    "with open('a_test.txt', 'w') as file_out:\n",
    "    file_out.write(data_to_write)\n",
    "\n",
    "# we can check that it worked by reading the file back in\n",
    "with open('a_test.txt', 'r') as file_in:\n",
    "    print(file_in.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can manipulate the filenames to create these new files dynamically on the fly. So, for example, we might want to create a series of closely related file names based on the connections among the documents. This might be called for when chunking a larger text document into a series of pieces. So let's use some code from the \"Chunking of this book. The code will be explained later, but for now suffice to say that the first function will take a text and divide it into a specified number of units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/iliad-0.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6cf5c3e4b07d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Note that when we use the counter in the filename we have to change it into a string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/iliad-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mfile_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/iliad-0.txt'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# will be explianed further in the chunking section.\n",
    "def get_chunks(text, num_chunks):\n",
    "    text_length = len(text)\n",
    "    text_chunks = []\n",
    "    number_of_chunks = num_chunks\n",
    "    for i in range(number_of_chunks):\n",
    "        chunk_size = text_length/number_of_chunks\n",
    "        chunk_start = math.floor(chunk_size * i)\n",
    "        chunk_end = math.floor(chunk_size * (i +1))\n",
    "        text_chunks.append(text[chunk_start:chunk_end])\n",
    "    return text_chunks\n",
    "\n",
    "# reads in the iliad and breaks it into 100 pieces.\n",
    "with open('iliad.txt', 'r') as file_in:\n",
    "    text = file_in.read()\n",
    "chunks = get_chunks(text, 100)\n",
    "\n",
    "# takes the pieces of the iliad and writes each of them to a new file with a filename based on a counter. We collect these into the output folder\n",
    "counter = 0\n",
    "for chunk in chunks:\n",
    "    # Note that when we use the counter in the filename we have to change it into a string.\n",
    "    with open('output/iliad-' + str(counter) + '.txt', 'w') as file_out:\n",
    "        file_out.write(chunk)\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The os library can help us prevent overwriting files if they already exist and, conversely, making sure that the appropriate folders exist for the code to run. If, for example, we could not run the previous code block without actually creating an 'output' folder. It would have errored. The os library can help check to make sure the required folders exist and, if not, create them for us within the program itself. We can use isfile() or isdir() to check that a particular thing exists, but exists() will check on both for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No worries - output exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.exists('output'):\n",
    "    print(\"No worries - output exists\")\n",
    "else:\n",
    "    print(\"Need to make the output folder. Making it now.\")\n",
    "    os.mkdir('output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we might put this together with the previous example to chunk, check if the output folder exists, and, if not, make the folder for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to make the output folder. Making it now.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# will be explianed further in the chunking section.\n",
    "def get_chunks(text, num_chunks):\n",
    "    text_length = len(text)\n",
    "    text_chunks = []\n",
    "    number_of_chunks = num_chunks\n",
    "    for i in range(number_of_chunks):\n",
    "        chunk_size = text_length/number_of_chunks\n",
    "        chunk_start = math.floor(chunk_size * i)\n",
    "        chunk_end = math.floor(chunk_size * (i +1))\n",
    "        text_chunks.append(text[chunk_start:chunk_end])\n",
    "    return text_chunks\n",
    "\n",
    "# reads in the iliad and breaks it into 100 pieces.\n",
    "with open('iliad.txt', 'r') as file_in:\n",
    "    text = file_in.read()\n",
    "chunks = get_chunks(text, 100)\n",
    "\n",
    "if os.path.exists('output'):\n",
    "    print(\"No worries - output exists\")\n",
    "else:\n",
    "    print(\"Need to make the output folder. Making it now.\")\n",
    "    os.mkdir('output')\n",
    "\n",
    "# takes the pieces of the iliad and writes each of them to a new file with a filename based on a counter. We collect these into the output folder\n",
    "counter = 0\n",
    "for chunk in chunks:\n",
    "    # Note that when we use the counter in the filename we have to change it into a string.\n",
    "    with open('output/iliad-' + str(counter) + '.txt', 'w') as file_out:\n",
    "        file_out.write(chunk)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulating the file structure like this is often one of the first steps in making the leap from introductory programming exercises to a full-on natural language processing project. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
