{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with plain text files\n",
    "\n",
    "One of the most common formats for working with text files is the .txt format. But there are actually a number of different potential ways to work with one of these files. One of the most basic uses a with statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'corpus/1915_the_voyage_out.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2c3e80b28eef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'corpus/1915_the_voyage_out.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_in\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'corpus/1915_the_voyage_out.txt'"
     ]
    }
   ],
   "source": [
    "filename = 'corpus/1915_the_voyage_out.txt'\n",
    "with open(filename, 'r') as file_in:\n",
    "    text = file_in.read()\n",
    "print(text[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we open the file and assign it a new, temporary name for the duration of the statement. This ensures that the file is opened, dealt with, and then closed safely. Once we un-indent, we have closed the file, and if we tried to read the same file again we would get a ValueError for trying to work with a closed file. The 'as file_in' bit assigns it to a variable so as to help us organize what is happening (we might have another file that we are writing to. Text is now one long string, which is fine in certain cases, but we could also read the contents of it in line by line. Here is a variation on the same approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'corpus/1915_the_voyage_out.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4895da0e6099>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'corpus/1915_the_voyage_out.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_in\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'corpus/1915_the_voyage_out.txt'"
     ]
    }
   ],
   "source": [
    "filename = 'corpus/1915_the_voyage_out.txt'\n",
    "with open(filename, 'r') as file_in:\n",
    "    text = file_in.readlines()\n",
    "print(text[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"readlines()\" function allows us to take an open file and read it line by line, returning a list of the lines. We assign that list to the text variable here, which we can now use to examine particular parts of the text. Note that here the line breaks do not correspond to sentences. Dividing longer chunks of text into sentences is a separate technique entirely, one called segmentation, that we'll get into later. For now, though, note how this means that the steps required to process your data in the way that you require depend entirely on the way in which it was encoded. In some cases, line breaks can be quite useful, say, when working with poetry where the line breaks are especially meaningful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'corpus/sonnet_one.txt'\n",
    "with open(filename, 'r') as file_in:\n",
    "    poetry = file_in.readlines()\n",
    "print(poetry[:12])\n",
    "print('=====')\n",
    "print(poetry[12:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling readlines() on a piece of poetry gives us access to the whole poem as a list of lines, so we can manipulate it to chunk the poem into pieces that we care about. Above, I separated the poem into two pieces at the volta, the turn in the sonnet that occurs before the couplet.\n",
    "\n",
    "Those '\\n' characters might appear to be a mistake at first, but worry not! They are actually the computer's representation of a newline character, a way of knowing when a line break happens. Before we process these for analysis, we would want to process those out. One way would be to search each string and remove the character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned_poem = []\n",
    "for line in poetry:\n",
    "    clean_line = line.replace('\\n', '')\n",
    "    cleaned_poem.append(clean_line)\n",
    "\n",
    "print(cleaned_poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This points to an important underlying problem in natural language processing: these texts are not formatted in such a way that they are computer ready right away. That's what puts the natural in natural language! In the case of prose, you can expect a few different categories:\n",
    "\n",
    "1. The text is one continuous string with no line breaks.\n",
    "2. The text has line breaks that correspond to the ends of the lines as laid out on a page.\n",
    "3. The text has line breaks that correspond to meaningful categories.\n",
    "4. Some combination of 2 and 3 (most likely).\n",
    "\n",
    "In most cases, as when working with prose, the line breaks will be used to shape the legibility of a text. Ie - they are meant to assist with the typographical layout, but they have no underlying interpretive meaning. This means that if you wish to preserve the underlying structure of a text you will need to parse the text in a more sophisticated way than just reading it in either as a lump or line by line.\n",
    "\n",
    "Of course, nothing will be as reliable as separating things individually by hand. In the case of a book of poetry, you might, for example, separate each poem into its own text file. The sonnets folder has a set of five Shakespearean sonnets in it. Combining what we've learned already, we can read the filenames from the folder, read them each in, and then store them in a variable for manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = glob.glob('corpus/sonnets/*.txt')\n",
    "sonnets = []\n",
    "for filename in filenames:\n",
    "    with open(filename, 'r') as file_in:\n",
    "        sonnets.append(file_in.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list called sonnets, but it's more properly understood as a list of lists, or a list in which each item is itself a list of more items:\n",
    "\n",
    "* List level one: sonnet level.\n",
    "* List level two (sub-list): line level.\n",
    "\n",
    "And we can manipulate this hierarchy to access different elements of the list. This will give us the first sonnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sonnets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sonnets[2][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizing things manually like this gives you great control over the files you're working with and their underlying structure. When working with a large corpus you might not have such an option. Separating files by hand is feasible when working with a few texts, but when working with thousands of documents you either have to work with what they give you or develop some computational way of recovering the structure of your text. In these cases, you might rely on textual markers to pinpoint sections of a text.\n",
    "\n",
    "Pinpoint by chapter markers.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
